{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from sdk.sdk import example_payload, example_completion_payload\n",
    "from loguru import logger\n",
    "import httpx\n",
    "import json\n",
    "from sdk import sdk\n",
    "\n",
    "async def get_real_response( payload: dict[str, Any] = example_payload, llm_url: str | None = None, chat: bool = True) -> dict[str, Any]:\n",
    "    if llm_url is None:\n",
    "        logger.warning(\"No LLM URL provided, using default\")\n",
    "        llm_url = \"http://llm_server:8000\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        if chat:\n",
    "            response = await client.post(llm_url.rstrip(\"/\") + \"/v1/chat/completions\", json=payload)\n",
    "        else:\n",
    "            response = await client.post(llm_url.rstrip(\"/\") + \"/v1/completions\", json=payload)\n",
    "        if response.status_code != 200:\n",
    "            logger.error(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "        messages= []\n",
    "        async for chunk in response.aiter_lines():\n",
    "            if \"data: {\" not in chunk:\n",
    "                continue\n",
    "            data = json.loads(chunk.split(\"data: \")[1])\n",
    "            logprobs = data[\"choices\"][0][\"logprobs\"]\n",
    "            if logprobs is None:\n",
    "                continue\n",
    "            messages.append(data)\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 12:42:57.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.sdk\u001b[0m:\u001b[36mcheck_result\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mGot task ID: bd993bb4-65dc-493b-855f-509559d5d26a !!!\u001b[0m\n",
      "\u001b[32m2024-12-03 12:42:57.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task bd993bb4-65dc-493b-855f-509559d5d26a to be done - check number: 1\u001b[0m\n",
      "\u001b[32m2024-12-03 12:42:59.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task bd993bb4-65dc-493b-855f-509559d5d26a to be done - check number: 2\u001b[0m\n",
      "\u001b[32m2024-12-03 12:43:00.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mTask bd993bb4-65dc-493b-855f-509559d5d26a is done: {'task_id': 'bd993bb4-65dc-493b-855f-509559d5d26a', 'result': {'node_scores': {'0': 0.8182241655025319}, 'timestamp': '2024-12-03T11:43:00.164584', 'error_message': None, 'traceback': None}, 'status': 'Success'}\u001b[0m\n",
      "\u001b[32m2024-12-03 12:43:00.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.sdk\u001b[0m:\u001b[36mcheck_result\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mTask bd993bb4-65dc-493b-855f-509559d5d26a is done: ({'node_scores': {'0': 0.8182241655025319}, 'timestamp': '2024-12-03T11:43:00.164584', 'error_message': None, 'traceback': None}, 0)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'node_scores': {'0': 0.8182241655025319},\n",
       "  'timestamp': '2024-12-03T11:43:00.164584',\n",
       "  'error_message': None,\n",
       "  'traceback': None},\n",
       " 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for chat \n",
    "payload = example_payload.copy()\n",
    "payload[\"model\"] = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "messages = await get_real_response(payload=payload, chat=True, llm_url=\"http://83.143.115.20:8000\")\n",
    "await sdk.check_result(task=\"chat-llama-3-2-3b\", orchestrator_url=\"http://83.143.115.20:6920/\", miner_response=messages[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-01 20:31:57.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.sdk\u001b[0m:\u001b[36mcheck_result\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mGot task ID: 3b0745ac-0a25-44fa-a012-07fe3343eef1 !!!\u001b[0m\n",
      "\u001b[32m2024-12-01 20:31:57.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task 3b0745ac-0a25-44fa-a012-07fe3343eef1 to be done - check number: 1\u001b[0m\n",
      "\u001b[32m2024-12-01 20:31:58.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task 3b0745ac-0a25-44fa-a012-07fe3343eef1 to be done - check number: 2\u001b[0m\n",
      "\u001b[32m2024-12-01 20:32:00.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mTask 3b0745ac-0a25-44fa-a012-07fe3343eef1 is done: {'task_id': '3b0745ac-0a25-44fa-a012-07fe3343eef1', 'result': {'node_scores': {'0': 1.0}, 'timestamp': '2024-12-01T19:31:59.446511', 'error_message': None, 'traceback': None}, 'status': 'Success'}\u001b[0m\n",
      "\u001b[32m2024-12-01 20:32:00.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.sdk\u001b[0m:\u001b[36mcheck_result\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mTask 3b0745ac-0a25-44fa-a012-07fe3343eef1 is done: ({'node_scores': {'0': 1.0}, 'timestamp': '2024-12-01T19:31:59.446511', 'error_message': None, 'traceback': None}, 0)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'node_scores': {'0': 1.0},\n",
       "  'timestamp': '2024-12-01T19:31:59.446511',\n",
       "  'error_message': None,\n",
       "  'traceback': None},\n",
       " 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for chat \n",
    "payload = example_completion_payload.copy()\n",
    "payload[\"model\"] = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "messages = await get_real_response(payload=payload, chat=False, llm_url=\"http://83.143.115.20:8000\")\n",
    "await sdk.check_result(task=\"chat-llama-3-2-3b\", payload=payload, orchestrator_url=\"http://83.143.115.20:6920/\", miner_response=messages[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-30 20:07:47.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1m{'count': 16, 'max_model_len': 20000, 'tokens': [128000, 128006, 882, 128007, 271, 9906, 11, 1268, 527, 499, 30, 128009, 128006, 78191, 128007, 271]}\u001b[0m\n",
      "\u001b[32m2024-11-30 20:07:47.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m{'id': 'cmpl-6dca6c5b5044417b9db7a3d0f1f9375f', 'object': 'text_completion', 'created': 1732993667, 'model': 'unsloth/Meta-Llama-3.1-8B-Instruct', 'choices': [{'index': 0, 'text': \"I'm just a computer program, so I don\", 'logprobs': None, 'finish_reason': 'length', 'stop_reason': None, 'prompt_logprobs': None}], 'usage': {'prompt_tokens': 16, 'total_tokens': 26, 'completion_tokens': 10}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from loguru import logger\n",
    "\n",
    "def tokenize_message(url, payload):\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        logger.error(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "def generate_completions(url, payload):\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        logger.error(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    tokenize_url = \"http://83.143.115.20:8000/tokenize\"\n",
    "    completions_url = \"http://83.143.115.20:8000/v1/completions\"\n",
    "\n",
    "    tokenize_payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
    "        ],\n",
    "        \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "    }\n",
    "\n",
    "    tokenize_response = tokenize_message(tokenize_url, tokenize_payload)\n",
    "    if tokenize_response is not None:\n",
    "        logger.info(tokenize_response)\n",
    "        completions_payload = {\n",
    "            \"prompt\": tokenize_response[\"tokens\"],\n",
    "            \"max_tokens\": 10,\n",
    "            \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "        }\n",
    "        completions_response = generate_completions(completions_url, completions_payload)\n",
    "        if completions_response is not None:\n",
    "            logger.info(completions_response)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://83.143.115.20:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "async def apply_chat_template(messages: list[dict], model: str = \"unsloth/Meta-Llama-3.1-8B-Instruct\", eot_id: int = 128009, add_generation_prompt: bool = True):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.post(url=f\"{BASE_URL}/tokenize\", json={\"model\": model, \"messages\": messages})\n",
    "        r.raise_for_status()  # raise an exception for 4xx or 5xx status codes\n",
    "        tokens: list[int] = r.json()[\"tokens\"]\n",
    "        if \"llama-3\" in model.lower() and not add_generation_prompt:\n",
    "            index_of_last_eot_id = max((loc for loc, val in enumerate(tokens) if val == eot_id), default=None)\n",
    "            if index_of_last_eot_id is not None:\n",
    "                tokens = tokens[:index_of_last_eot_id]\n",
    "        \n",
    "        r2 = await client.post(url=f\"{BASE_URL}/detokenize\", json={\"tokens\": tokens, \"model\": model})\n",
    "        r2.raise_for_status()  # raise an exception for 4xx or 5xx status codes\n",
    "        \n",
    "        prompt = r2.json()[\"prompt\"]\n",
    "        return prompt, len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def tokenize(prompt: str, model: str = \"unsloth/Meta-Llama-3.1-8B-Instruct\"):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.post(url=f\"{BASE_URL}/tokenize\", json={\"model\": model, \"prompt\": prompt})\n",
    "        r.raise_for_status()  # raise an exception for 4xx or 5xx status codes\n",
    "        return r.json()[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def detokenize(tokens: list[int], model: str = \"unsloth/Meta-Llama-3.1-8B-Instruct\"):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.post(url=f\"{BASE_URL}/detokenize\", json={\"tokens\": tokens, \"model\": model})\n",
    "        r.raise_for_status()  # raise an exception for 4xx or 5xx status codes\n",
    "        return r.json()[\"prompt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '!N<|eot_id|>--9'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with httpx.AsyncClient() as client:\n",
    "    r = await client.post(url=f\"{BASE_URL}/detokenize\", json={\"tokens\": [0, 45, 128009, 12, 12, 24], \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\"})\n",
    "    r.raise_for_status()  # raise an exception for 4xx or 5xx status codes\n",
    "    r.json()\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fjson(r: list[dict]):\n",
    "    for d in r:\n",
    "        for p in d.values():\n",
    "            p[\"logprob\"] = round(float(p[\"logprob\"]), 2)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you? respond in 3 words<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n',\n",
       " 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the input prompt & chat messages\n",
    "input_messages = [    \n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you? respond in 3 words\"},\n",
    "]\n",
    "prompt, num_input_tokens = await apply_chat_template(\n",
    "    messages=input_messages,\n",
    "    model=\"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    eot_id=128009,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "prompt, num_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the response from completions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_stop_str_in_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m })\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(r\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     11\u001b[0m content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(r\u001b[38;5;241m.\u001b[39mtext)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the response from completions\n",
    "r = requests.post(f\"{BASE_URL}/v1/completions\", json={\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 30,\n",
    "    \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"temperature\": 1.0,\n",
    "    \"include_stop_str_in_output\": True,\n",
    "})\n",
    "\n",
    "print(r.status_code)\n",
    "content = json.loads(r.text)[\"choices\"][0][\"text\"]\n",
    "content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full response\n",
    "response = prompt + content\n",
    "response_tokens = await tokenize(response, \"unsloth/Meta-Llama-3.1-8B-Instruct\")\n",
    "if response_tokens[-1] != 128009:\n",
    "    response_tokens.append(128009)\n",
    "response = await detokenize(response_tokens, \"unsloth/Meta-Llama-3.1-8B-Instruct\")\n",
    "chat_response = input_messages + [{\"role\": \"assistant\", \"content\": content}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 2846, 3815, 7060, 13]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await tokenize(content, \"unsloth/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse_tokens\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "response_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'40': {'logprob': -0.0076646762900054455, 'rank': 1, 'decoded_token': 'I'},\n",
       "  '84146': {'logprob': -5.445164680480957,\n",
       "   'rank': 2,\n",
       "   'decoded_token': 'Doing'}},\n",
       " {'2846': {'logprob': -0.10332441329956055, 'rank': 1, 'decoded_token': \"'m\"},\n",
       "  '1097': {'logprob': -2.3220744132995605, 'rank': 2, 'decoded_token': ' am'}},\n",
       " {'3815': {'logprob': -0.61980140209198, 'rank': 1, 'decoded_token': ' doing'},\n",
       "  '31301': {'logprob': -0.86980140209198,\n",
       "   'rank': 2,\n",
       "   'decoded_token': ' functioning'}},\n",
       " {'7060': {'logprob': -2.8158586025238037,\n",
       "   'rank': 3,\n",
       "   'decoded_token': ' fine'},\n",
       "  '1664': {'logprob': -0.5502336621284485,\n",
       "   'rank': 1,\n",
       "   'decoded_token': ' well'},\n",
       "  '2294': {'logprob': -1.0189836025238037,\n",
       "   'rank': 2,\n",
       "   'decoded_token': ' great'}},\n",
       " {'13': {'logprob': -0.2513454854488373, 'rank': 1, 'decoded_token': '.'},\n",
       "  '128009': {'logprob': -1.9075955152511597, 'rank': 2, 'decoded_token': ''}},\n",
       " {'128009': {'logprob': -9.035655966727063e-05,\n",
       "   'rank': 1,\n",
       "   'decoded_token': ''},\n",
       "  '9930': {'logprob': -9.875090599060059,\n",
       "   'rank': 2,\n",
       "   'decoded_token': ' Thank'}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prompt logprobs from completions\n",
    "r = requests.post(f\"{BASE_URL}/v1/completions\", json={\n",
    "    \"prompt\": response,\n",
    "    \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"temperature\": 1.0,\n",
    "    \"max_tokens\": 1,\n",
    "    \"prompt_logprobs\": 2\n",
    "})\n",
    "\n",
    "print(r.status_code)\n",
    "result = json.loads(r.text)\n",
    "# result[\"prompt_logprobs\"]\n",
    "result[\"choices\"][0][\"prompt_logprobs\"][num_input_tokens:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'40': {'logprob': -0.01, 'rank': 1, 'decoded_token': 'I'},\n",
       "  '84146': {'logprob': -5.45, 'rank': 2, 'decoded_token': 'Doing'}},\n",
       " {'2846': {'logprob': -0.1, 'rank': 1, 'decoded_token': \"'m\"},\n",
       "  '1097': {'logprob': -2.32, 'rank': 2, 'decoded_token': ' am'}},\n",
       " {'3815': {'logprob': -0.62, 'rank': 1, 'decoded_token': ' doing'},\n",
       "  '31301': {'logprob': -0.87, 'rank': 2, 'decoded_token': ' functioning'}},\n",
       " {'7060': {'logprob': -2.82, 'rank': 3, 'decoded_token': ' fine'},\n",
       "  '1664': {'logprob': -0.55, 'rank': 1, 'decoded_token': ' well'},\n",
       "  '2294': {'logprob': -1.02, 'rank': 2, 'decoded_token': ' great'}},\n",
       " {'13': {'logprob': -0.25, 'rank': 1, 'decoded_token': '.'},\n",
       "  '128009': {'logprob': -1.91, 'rank': 2, 'decoded_token': ''}},\n",
       " {'128009': {'logprob': -0.0, 'rank': 1, 'decoded_token': ''},\n",
       "  '9930': {'logprob': -9.88, 'rank': 2, 'decoded_token': ' Thank'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_logprobs_to_check = _fjson(result[\"choices\"][0][\"prompt_logprobs\"][num_input_tokens:])\n",
    "prompt_logprobs_to_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-f2fb4d973c8f4128b1120ccb8c9e0538',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1732993583,\n",
       " 'model': 'unsloth/Meta-Llama-3.1-8B-Instruct',\n",
       " 'choices': [{'index': 0,\n",
       "   'text': '.',\n",
       "   'logprobs': {'text_offset': [0],\n",
       "    'token_logprobs': [-0.2513526976108551],\n",
       "    'tokens': ['.'],\n",
       "    'top_logprobs': [{'.': -0.2513526976108551,\n",
       "      '': -1.9076026678085327,\n",
       "      ' thanks': -3.5794777870178223,\n",
       "      ' thank': -3.6576027870178223,\n",
       "      ' today': -4.298227787017822}]},\n",
       "   'finish_reason': 'length',\n",
       "   'stop_reason': None,\n",
       "   'prompt_logprobs': None}],\n",
       " 'usage': {'prompt_tokens': 25, 'total_tokens': 26, 'completion_tokens': 1}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check random token\n",
    "\n",
    "r = requests.post(f\"{BASE_URL}/v1/completions\", json={\n",
    "    \"prompt\": await detokenize(response_tokens[:-2], \"unsloth/Meta-Llama-3.1-8B-Instruct\"),\n",
    "    \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 1,\n",
    "    # \"prompt_logprobs\": 1,\n",
    "    \"logprobs\": 5,\n",
    "})\n",
    "\n",
    "print(r.status_code)\n",
    "result = json.loads(r.text)\n",
    "result\n",
    "# result[\"choices\"][0][\"prompt_logprobs\"][num_input_tokens:]\n",
    "# result[\"logprobs\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response\n",
    "fake_chat_response = [{\"role\": \"user\", \"content\": \"Hello, how are you? respond in 3 words\"}, {\"role\": \"assistant\", \"content\": \"I'm doing\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chat-e2bbd310ca9947cca336b0a4b4b06751',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1732993403,\n",
       " 'model': 'unsloth/Meta-Llama-3.1-8B-Instruct',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant', 'content': 'well,', 'tool_calls': []},\n",
       "   'logprobs': {'content': [{'token': 'well',\n",
       "      'logprob': -0.958371102809906,\n",
       "      'bytes': [119, 101, 108, 108],\n",
       "      'top_logprobs': [{'token': 'well',\n",
       "        'logprob': -0.958371102809906,\n",
       "        'bytes': [119, 101, 108, 108]},\n",
       "       {'token': 'great',\n",
       "        'logprob': -1.4271211624145508,\n",
       "        'bytes': [103, 114, 101, 97, 116]},\n",
       "       {'token': 'fine',\n",
       "        'logprob': -2.177121162414551,\n",
       "        'bytes': [102, 105, 110, 101]},\n",
       "       {'token': 'pretty',\n",
       "        'logprob': -3.286496162414551,\n",
       "        'bytes': [112, 114, 101, 116, 116, 121]},\n",
       "       {'token': 'very',\n",
       "        'logprob': -3.489621162414551,\n",
       "        'bytes': [118, 101, 114, 121]}]},\n",
       "     {'token': ',',\n",
       "      'logprob': -0.41791412234306335,\n",
       "      'bytes': [44],\n",
       "      'top_logprobs': [{'token': ',',\n",
       "        'logprob': -0.41791412234306335,\n",
       "        'bytes': [44]},\n",
       "       {'token': ' thank',\n",
       "        'logprob': -1.8241641521453857,\n",
       "        'bytes': [32, 116, 104, 97, 110, 107]},\n",
       "       {'token': ' thanks',\n",
       "        'logprob': -2.2304141521453857,\n",
       "        'bytes': [32, 116, 104, 97, 110, 107, 115]},\n",
       "       {'token': ' today',\n",
       "        'logprob': -3.2772891521453857,\n",
       "        'bytes': [32, 116, 111, 100, 97, 121]},\n",
       "       {'token': ' enough',\n",
       "        'logprob': -4.417913913726807,\n",
       "        'bytes': [32, 101, 110, 111, 117, 103, 104]}]}]},\n",
       "   'finish_reason': 'length',\n",
       "   'stop_reason': None}],\n",
       " 'usage': {'prompt_tokens': 29, 'total_tokens': 31, 'completion_tokens': 2},\n",
       " 'prompt_logprobs': None}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check end of token\n",
    "r = requests.post(f\"{BASE_URL}/v1/chat/completions\", json={\n",
    "    \"messages\": fake_chat_response,\n",
    "    \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 2,\n",
    "    \"logprobs\": True,\n",
    "    \"top_logprobs\": 5,\n",
    "    \"add_generation_prompt\": True,\n",
    "    \"add_special_tokens\": False,\n",
    "    \"include_stop_str_in_output\": True,\n",
    "    \"top_k\": 5,\n",
    "})\n",
    "\n",
    "print(r.status_code)\n",
    "result = json.loads(r.text)\n",
    "# result[\"logprobs\"][-1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {\"count\":16,\"max_model_len\":20000,\"tokens\":[128000,128006,882,128007,271,9906,11,1268,527,499,30,128009,128006,78191,128007,271]}\n",
      "{'count': 16, 'max_model_len': 20000, 'tokens': [128000, 128006, 882, 128007, 271, 9906, 11, 1268, 527, 499, 30, 128009, 128006, 78191, 128007, 271]}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(url=f\"{BASE_URL}/tokenize\", json={\n",
    "    \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"I am good\"},\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(r.status_code, r.text)\n",
    "print(r.json())\n",
    "\n",
    "tokens = r.json()[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {\"prompt\":\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"}\n",
      "{'prompt': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(url=f\"{BASE_URL}/detokenize\", json={\n",
    "    \"tokens\": tokens,\n",
    "    \"model\": \"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
    "})\n",
    "print(r.status_code, r.text)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdk import sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-23 21:54:28.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.sdk\u001b[0m:\u001b[36mcheck_result\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mGot task ID: dab8de1c-076c-491e-93e8-a4f96c9b61ee !!!\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:28.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 1\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 2\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:31.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 3\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:32.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 4\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:33.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 5\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:35.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 6\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:37.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 7\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:38.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 8\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:39.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 9\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:40.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 10\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:42.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 11\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:43.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 12\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:44.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 13\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:45.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 14\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:47.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 15\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:48.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 16\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:49.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 17\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:50.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 18\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:52.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 19\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:53.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 20\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:54.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 21\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:55.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 22\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:57.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 23\u001b[0m\n",
      "\u001b[32m2024-11-23 21:54:58.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 24\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:00.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 25\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:01.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 26\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:03.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 27\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:04.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 28\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:05.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 29\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:06.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 30\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:08.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 31\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:09.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 32\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:10.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 33\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:12.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 34\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:13.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 35\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:14.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 36\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:16.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 37\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:17.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 38\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:18.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 39\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:20.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 40\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:21.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 41\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:22.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 42\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:24.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 43\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:25.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 44\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:26.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 45\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:27.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 46\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:29.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 47\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:30.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 48\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:31.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 49\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:32.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 50\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:34.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 51\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:35.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 52\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:36.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 53\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:37.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 54\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:38.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 55\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:40.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 56\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:41.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 57\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:42.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 58\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:43.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 59\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:45.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 60\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:46.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 61\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:47.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 62\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:48.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mWaiting for task dab8de1c-076c-491e-93e8-a4f96c9b61ee to be done - check number: 63\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:49.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.orchestrator_handling\u001b[0m:\u001b[36mhandle_task_id\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mTask dab8de1c-076c-491e-93e8-a4f96c9b61ee is done: {'task_id': 'dab8de1c-076c-491e-93e8-a4f96c9b61ee', 'result': {'node_scores': {'0': 0.0}, 'timestamp': '2024-11-23T20:55:49.764517', 'error_message': None, 'traceback': None}, 'status': 'Success'}\u001b[0m\n",
      "\u001b[32m2024-11-23 21:55:49.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msdk.sdk\u001b[0m:\u001b[36mcheck_result\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mTask dab8de1c-076c-491e-93e8-a4f96c9b61ee is done: ({'node_scores': {'0': 0.0}, 'timestamp': '2024-11-23T20:55:49.764517', 'error_message': None, 'traceback': None}, 0)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'node_scores': {'0': 0.0},\n",
       "  'timestamp': '2024-11-23T20:55:49.764517',\n",
       "  'error_message': None,\n",
       "  'traceback': None},\n",
       " 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
