**Vision LLM inference server**

LLM server (runs both mixtral and finetune)

Some installation docs:

1. [Base installation - works for most](docs/installation_base.md)